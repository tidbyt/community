"""
Applet: GPT Color
Summary: Random Colors Generated by Chat GPT
Description: GPT 3.5 is queried to generate random colors for display every 30 minutes
Author: Hadlich Labs
"""

load("cache.star", "cache")
load("http.star", "http")
load("random.star", "random")
load("render.star", "render")
load("schema.star", "schema")

# URL used for chat completions
OPENAI_COMPLETION_URL = "https://api.openai.com/v1/chat/completions"

# URL used to check for models and validate OPENAI_API_KEY
OPENAI_MODELS_URL = "https://api.openai.com/v1/models"

# Open AI model used
OPENAI_COMPLETION_MODEL = "gpt-3.5-turbo"

# Wait 15 minutes before checking if key is valid again
INVALID_KEY_COOLOFF_TTL_SECONDS = 15 * 60

# Validates OPENAI_API_KEY
def validate_key(OPENAI_API_KEY):
    response_art = cache.get("response_art-" + OPENAI_API_KEY)

    if response_art != None:
        # We've seen this and generated an art, return True
        return True, "Valid Key Found"

    # The key has not been seen or not been seen since last generation
    # Check if it was previously checked
    previously_invalid = cache.get("invalid_key-" + OPENAI_API_KEY)

    if previously_invalid != None:
        # We've seen this and it was invalid previously
        return False, previously_invalid

    # The key has not been seen or validated in a while
    print("Calling API to validate OPENAI_API_KEY")

    # Example Models Call
    ### curl https://api.openai.com/v1/models/ \
    ###   -H "Authorization: Bearer $OPENAI_API_KEY"

    rep = http.get(
        OPENAI_MODELS_URL,
        headers = {"Authorization": "Bearer " + OPENAI_API_KEY},
    )

    #print(rep.json())
    response = rep.json()

    if rep.status_code == 200:
        # Check if API has access to OPENAI_COMPLETION_MODEL
        if "data" in response:
            models = response["data"]
            for model in models:
                if "id" in model and OPENAI_COMPLETION_MODEL in model["id"]:
                    # User has valid API Key and access to model
                    return True, "Valid Key Found"

        error_code = "OpenAI: Key provided does not have access to " + OPENAI_COMPLETION_MODEL

        # TODO: Determine if this cache call can be converted to the new HTTP cache.
        cache.set("invalid_key-" + OPENAI_API_KEY, error_code, ttl_seconds = INVALID_KEY_COOLOFF_TTL_SECONDS)
        return False, error_code

    # Got a negative response from OpenAI
    error_code = None
    if "error" in response and "code" in response["error"]:
        error_code = "Open AI: " + response["error"]["code"]
    else:
        error_code = "Open AI: Response " + str(rep.status_code)

    # TODO: Determine if this cache call can be converted to the new HTTP cache.
    cache.set("invalid_key-" + OPENAI_API_KEY, error_code, ttl_seconds = INVALID_KEY_COOLOFF_TTL_SECONDS)
    return False, error_code

# Show an canned graphic
def defaultGraphic(type):
    art = "#f2c4d1,#9c4f8d,#f4a460,#c0c0c0,#8b008b,#008b8b,#f5deb3,#ff8c00,#00ff7f,#d2691e,#ff7f50,#ff1493,#00ffff,#87cefa,#7fffd4,#dda0dd,#7b68ee,#ff4500,#fa8072,#00fa9a,#1e90ff,#ff69b4,#ff00ff,#ff0000,#00ff00,#0000ff,#8a2be2,#a0522d,#b22222,#dc143c,#ff69b4,#00bfff"
    children = []
    for c in art.split(","):
        children.append(render.Box(width = 2, height = 24, color = c))

    return render.Root(
        child = render.Stack(
            children = [
                render.Row(
                    children = children,
                ),
                render.Column(
                    main_align = "center",
                    cross_align = "center",
                    expanded = True,
                    children = [
                        render.Text("", color = "#FFFFFF"),
                        render.Text("", color = "#FFFFFF"),
                        render.Text("", color = "#FFFFFF"),
                        render.Marquee(
                            width = 60,
                            scroll_direction = "horizontal",
                            offset_start = 10,
                            offset_end = 10,
                            child = render.Text(type),
                        ),
                    ],
                ),
            ],
        ),
    )

def int_to_hex_string(number):
    hex_digits = "0123456789abcdef"
    hex_str = ""
    working_number = int(number)
    for _ in range(6):
        remainder = working_number % 16
        hex_str = hex_digits[remainder] + hex_str
        working_number = working_number // 16
    return hex_str

def generate_random_hex():
    # Function if gpt doesn't do exactly what it is told
    random_int = random.number(0, 0xFFFFFF)
    hex_str = int_to_hex_string(random_int)

    generated = "#" + hex_str

    # print("Generated: %s" % generated)
    return generated

def is_valid_hex(hex_str):
    # Checks if input is valid hex number
    # print("Checking if valid color %s" % hex_str)
    if not (hex_str.startswith("#") and len(hex_str) == 7):
        # print("Invalid due to not right length or wrong start char: %s" % hex_str)
        return False

    str_check = "0123456789abcdefABCDEF"

    for i in range(len(hex_str[1:])):
        if hex_str[i + 1] not in str_check:
            return False

    return True

def request_art(OPENAI_API_KEY):
    print("Calling Completion API")

    # Example Completion Call
    ### curl https://api.openai.com/v1/chat/completions \
    ###   -H "Content-Type: application/json" \
    ###   -H "Authorization: Bearer $OPENAI_API_KEY" \
    ###   -d '{
    ###      "model": "gpt-3.5-turbo",
    ###      "messages": [{"role": "user", "content": "Say this is a test!"}],
    ###      "temperature": 0.7
    ###    }'

    prompt = [{"role": "system", "content": "You are a computer terminal, do not write code, only respond with CSVs. Respond only with \"#xxxxxx,#xxxxxx,#xxxxxx,...\" formatting."}, {"role": "user", "content": "Return 32 random hex colors in a csv, like a python function returning a string. Do not include newlines, do not include spaces, do not list, do not include header or comments. Each color should be different. Format the number #xxxxxx"}]

    rep = http.post(
        OPENAI_COMPLETION_URL,
        headers = {"Authorization": "Bearer " + OPENAI_API_KEY},
        json_body = {"model": OPENAI_COMPLETION_MODEL, "messages": prompt, "temperature": 0.3},
    )

    #print(rep.json())
    response = rep.json()
    if rep.status_code != 200:
        if "error" in response and "code" in response["error"]:
            error_code = "Open AI: " + response["error"]["code"]
        else:
            error_code = "Open AI: Response " + str(rep.status_code)
        return None, error_code

    valid_colors = []

    # response = {"created": 1.68162084e+09, "model": "gpt-3.5-turbo-0301", "usage": {"total_tokens": 329.0, "prompt_tokens": 99.0, "completion_tokens": 230.0}, "choices": [{"message": {"role": "assistant", "content": "#f0d2e3,#f3d6c7,#f8e6d0,#f6e5c6,#f0c8c9,#f7e9d1,#e0c8d8,#d6c7f3,#e2c8f8,#f8d6e5,#e5c6f6,#c8d8e0,#c7f3d6,#c8e2f8,#d6f8e5,#c6e5f6,#d8e0c8,#f3c7d6,#e2c8c8,#f8d6d6,#e5c6c6,#c8d8d8,#c7f3f3,#c8e2e2,#d6f8f8,#c6e5e5,#d8e0e0,#f3c7c7,#e2c8c8,#f8d6d6,#e5c6c6"}, "finish_reason": "stop", "index": 0.0}], "id": "chatcmpl-xxxxxx", "object": "chat.completion"}

    if "choices" in response and len(response["choices"]) > 0 and "message" in response["choices"][0] and "content" in response["choices"][0]["message"]:
        content = response["choices"][0]["message"]["content"]

        # print("Received from GPT: %s" % content)

        # Output should be #xxxxxx,#xxxxxx,#xxxxxx,...
        # Try to extract colors
        color_list = content.split(",")

        for c in color_list:
            # print("GPT Found Color %s" % c)
            if (is_valid_hex(c.strip())):
                valid_colors.append(c)

    print("Valid Colors from GPT: " + str(len(valid_colors)))

    colors_needed = 32 - len(valid_colors)
    if (colors_needed > 0):
        for _ in range(colors_needed):
            valid_colors.append(generate_random_hex())

    return ",".join(valid_colors[:32]), "Success"

def get_art(OPENAI_API_KEY, cache_ttl_seconds):
    response_art = cache.get("response_art-" + OPENAI_API_KEY)

    if response_art == None:
        response_art, error_code = request_art(OPENAI_API_KEY)
        if response_art == None:
            return response_art, error_code

        # TODO: Determine if this cache call can be converted to the new HTTP cache.
        cache.set("response_art-" + OPENAI_API_KEY, response_art, ttl_seconds = cache_ttl_seconds)

    # print(response_art)

    return response_art, "Success"

def main(config):
    OPENAI_API_KEY = config.get("OPENAI_API_KEY", "")
    if OPENAI_API_KEY == "":
        return defaultGraphic("Please add your OPENAI_API_KEY")

    key_valid, error_code = validate_key(OPENAI_API_KEY)

    if (key_valid == False):
        return defaultGraphic(error_code)

    cache_ttl_seconds = int(config.get("cache_ttl_min", "10")) * 60

    art, error_code = get_art(OPENAI_API_KEY, cache_ttl_seconds)

    if (art == None):
        return defaultGraphic(error_code)

    children = []
    for c in art.split(","):
        children.append(render.Box(width = 2, height = 32, color = c))

    return render.Root(
        child = render.Row(
            children = children,
        ),
    )

def get_schema():
    return schema.Schema(
        version = "1",
        fields = [
            schema.Text(
                id = "OPENAI_API_KEY",
                name = "OpenAI API Key",
                desc = "Access token provided by OpenAI",
                icon = "key",
                default = "",
            ),
            schema.Dropdown(
                id = "cache_ttl_min",
                name = "Refresh Time",
                desc = "Time Between Updates",
                icon = "clock",
                default = "10",
                options = [
                    schema.Option(display = "5 Mins", value = "5"),
                    schema.Option(display = "10 Mins", value = "10"),
                    schema.Option(display = "15 Mins", value = "15"),
                    schema.Option(display = "30 Mins", value = "30"),
                    schema.Option(display = "45 Mins", value = "45"),
                    schema.Option(display = "1 Hour", value = "60"),
                    schema.Option(display = "2 Hours", value = "120"),
                    schema.Option(display = "3 Hours", value = "180"),
                    schema.Option(display = "4 Hours", value = "240"),
                    schema.Option(display = "5 Hours", value = "300"),
                    schema.Option(display = "6 Hours", value = "360"),
                    schema.Option(display = "7 Hours", value = "420"),
                    schema.Option(display = "8 Hours", value = "480"),
                    schema.Option(display = "9 Hours", value = "540"),
                    schema.Option(display = "10 Hours", value = "600"),
                    schema.Option(display = "11 Hours", value = "660"),
                    schema.Option(display = "12 Hours", value = "720"),
                    schema.Option(display = "13 Hours", value = "780"),
                    schema.Option(display = "14 Hours", value = "840"),
                    schema.Option(display = "15 Hours", value = "900"),
                    schema.Option(display = "16 Hours", value = "960"),
                    schema.Option(display = "17 Hours", value = "1020"),
                    schema.Option(display = "18 Hours", value = "1080"),
                    schema.Option(display = "19 Hours", value = "1140"),
                    schema.Option(display = "20 Hours", value = "1200"),
                    schema.Option(display = "21 Hours", value = "1260"),
                    schema.Option(display = "22 Hours", value = "1320"),
                    schema.Option(display = "23 Hours", value = "1380"),
                    schema.Option(display = "Daily", value = "1440"),
                    schema.Option(display = "Weekly", value = "10080"),
                ],
            ),
        ],
    )
